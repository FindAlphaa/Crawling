{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네이버 카페 크롤링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options as ChromeOptions\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.alert import Alert\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests               \n",
    "import lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chrome option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = ChromeOptions()\n",
    "user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\"\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option('excludeSwitches', ['enable-logging']) # Usb Error ignore\n",
    "options.add_argument(\"no-sandbox\") \n",
    "options.add_argument(\"disable-infobars\")\n",
    "options.add_argument(\"--disable-extensions\")\n",
    "options.add_argument('user-agent='+ user_agent)\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-logging\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wake up\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "url = 'https://cafe.naver.com/vilab/ArticleList.nhn?search.clubid=11525920&search.boardtype=L'\n",
    "driver.get(url)\n",
    "\n",
    "driver.implicitly_wait(10)\n",
    "driver.switch_to.frame(\"cafe_main\")\n",
    "print(\"wake up\")\n",
    "\n",
    "time.sleep(1)\n",
    "naver_data = defaultdict(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title, Date, Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.switch_to.frame(\"cafe_main\")\n",
    "\n",
    "while(1):\n",
    "    href_list = []\n",
    "    button_table = driver.find_element(By.XPATH, \"//*[@id=\\\"main-area\\\"]/div[6]\")\n",
    "    buttons = button_table.find_elements(By.TAG_NAME,\"a\")\n",
    "\n",
    "    for button_link in buttons:\n",
    "        blink = button_link.get_attribute('href')\n",
    "        href_list.append(blink)\n",
    "    print(href_list)\n",
    "    for i in range(len(buttons)):\n",
    "        # button이 숫자가 아니면\n",
    "        #print(buttons[i].text)\n",
    "        if not (buttons[i].text.isdigit()):\n",
    "            continue\n",
    "        # page에 들어가기\n",
    "        driver.get(href_list[i])\n",
    "        time.sleep(2)\n",
    "        driver.implicitly_wait(10)\n",
    "        driver.switch_to.frame('cafe_main')\n",
    "        # 2023년인지 확인\n",
    "        cut = driver.find_element(By.XPATH, \"//*[@id=\\\"main-area\\\"]/div[4]/table/tbody/tr[1]/td[3]\").text\n",
    "        if \"2022\" in cut:\n",
    "            a = False\n",
    "            break\n",
    "        \n",
    "        #조회수\n",
    "        num_clicks = driver.find_elements(By.CLASS_NAME,\"td_view\")\n",
    "        for num_click in num_clicks:\n",
    "            naver_data['click'].append(num_click.text)\n",
    "\n",
    "        \n",
    "        #날짜\n",
    "        dates = driver.find_elements(By.CLASS_NAME,\"td_date\")\n",
    "        for date in dates:\n",
    "            naver_data['date'].append(date.text)\n",
    "    \n",
    "        #제목이랑 link 뽑기\n",
    "        titles = driver.find_elements(By.CLASS_NAME,\"article\")\n",
    "        for title in titles:\n",
    "            href = title.get_attribute('href')\n",
    "        \n",
    "            naver_data['title'].append(title.text)\n",
    "            naver_data['link'].append(href)\n",
    "\n",
    "        button_table = driver.find_element(By.XPATH, \"//*[@id=\\\"main-area\\\"]/div[6]\")\n",
    "        buttons = button_table.find_elements(By.TAG_NAME,\"a\")\n",
    "\n",
    "    next = driver.find_element(By.CLASS_NAME,'pgR')\n",
    "    next.click()\n",
    "    if a == False:\n",
    "        break\n",
    "\n",
    "min_length = min(len(lst) for lst in naver_data.values())\n",
    "trimmed_data = {key: lst[:min_length] for key, lst in naver_data.items()}\n",
    "df = pd.DataFrame(trimmed_data)\n",
    "df.to_csv(\"naver_data1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content, Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "naver_data = pd.read_csv(\"naver_data1.csv\")\n",
    "naver_data2 = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver.switch_to.frame('cafe_main')\n",
    "for link in naver_data['link']:\n",
    "    try:\n",
    "        driver.get(link)\n",
    "        time.sleep(1)\n",
    "        driver.switch_to.frame('cafe_main')\n",
    "        \n",
    "        req = driver.page_source\n",
    "        driver.implicitly_wait(10)\n",
    "        soup = BeautifulSoup(req, 'lxml')\n",
    "    except:\n",
    "        naver_data2['content'].append(None)\n",
    "        naver_data2['comment'].append(None)\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        content = soup.select(\".article_viewer\")\n",
    "\n",
    "    except:\n",
    "        naver_data2['content'].append(None)\n",
    "\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        comment = soup.select('.comment_text_view')\n",
    "\n",
    "    except:\n",
    "        naver_data2['comment'].append(None)\n",
    "        continue\n",
    "\n",
    "    text_comment = ''\n",
    "    text_content = ''\n",
    " \n",
    "    for c in comment:\n",
    "        text_comment  = text_comment +'\\n' +  c.text\n",
    "    \n",
    "    for c in content:\n",
    "        text_content  = text_content +'\\n' +  c.text\n",
    "\n",
    "    print(text_comment, text_content)\n",
    "    \n",
    "    naver_data2['content'].append(text_content)\n",
    "    naver_data2['comment'].append(text_comment)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_length = min(len(lst) for lst in naver_data2.values())\n",
    "trimmed_data = {key: lst[:min_length] for key, lst in naver_data2.items()}\n",
    "df = pd.DataFrame(trimmed_data)\n",
    "df.to_csv(\"naver_data_content.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
